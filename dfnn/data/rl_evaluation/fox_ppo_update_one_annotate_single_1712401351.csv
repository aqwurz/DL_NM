mean_reward,std_reward,non_timeout_share,goal_share,steps_per_successful_epsiode,variable_tiles_per_episode,name,num_episodes
0.258068777,0.42963953993498,0.325,0.266,8.481203007518797,0.015,"PPO, trained on next tile, single channel, annotated",1000
0.344704709,0.4662178658472349,0.531,0.354,7.468926553672317,0.119,"PPO, trained on next tile, single channel, annotated",1000
0.29175079400000004,0.44688130850584656,0.43,0.299,6.896321070234114,0.133,"PPO, trained on next tile, single channel, annotated",1000
0.31832854799999993,0.45664781568597224,0.497,0.328,8.387195121951219,0.107,"PPO, trained on next tile, single channel, annotated",1000
0.37985314800000003,0.47187205629238743,0.582,0.394,10.213197969543147,0.302,"PPO, trained on next tile, single channel, annotated",1000
0.39765821799999995,0.47710339257754447,0.594,0.411,9.233576642335766,0.126,"PPO, trained on next tile, single channel, annotated",1000
0.23415704099999998,0.41702316836100767,0.378,0.24,6.925,0.096,"PPO, trained on next tile, single channel, annotated",1000
0.396948868,0.4793906268938355,0.524,0.407,7.024570024570025,0.082,"PPO, trained on next tile, single channel, annotated",1000
0.267459013,0.4348119886538903,0.337,0.275,7.8,0.03,"PPO, trained on next tile, single channel, annotated",1000
0.26959769100000003,0.43543662732759575,0.385,0.278,8.597122302158274,0.057,"PPO, trained on next tile, single channel, annotated",1000
0.239709001,0.42094071093732305,0.319,0.245,6.142857142857143,0.028,"PPO, trained on next tile, single channel, annotated",1000
0.18179531399999999,0.3804321053648409,0.38,0.186,6.43010752688172,0.117,"PPO, trained on next tile, single channel, annotated",1000
0.28438010299999994,0.4439632924750022,0.391,0.291,6.470790378006873,0.049,"PPO, trained on next tile, single channel, annotated",1000
0.30641836100000003,0.45256768241239087,0.564,0.315,7.749206349206349,0.161,"PPO, trained on next tile, single channel, annotated",1000
0.369892205,0.47134741820594384,0.523,0.382,9.015706806282722,0.075,"PPO, trained on next tile, single channel, annotated",1000
0.071906643,0.2562599903148705,0.124,0.073,4.260273972602739,0.024,"PPO, trained on next tile, single channel, annotated",1000
0.31863751,0.4557206004097509,0.439,0.33,9.793939393939393,0.133,"PPO, trained on next tile, single channel, annotated",1000
0.21719413399999998,0.40683894033853996,0.29,0.222,6.157657657657658,0.043,"PPO, trained on next tile, single channel, annotated",1000
0.248399223,0.42450690958508475,0.404,0.256,8.4453125,0.07,"PPO, trained on next tile, single channel, annotated",1000
0.354109022,0.4694127822479885,0.455,0.363,6.966942148760331,0.048,"PPO, trained on next tile, single channel, annotated",1000
0.327223465,0.4613442389641327,0.432,0.335,6.602985074626866,0.045,"PPO, trained on next tile, single channel, annotated",1000
0.200053534,0.3940926312850861,0.289,0.205,6.863414634146341,0.041,"PPO, trained on next tile, single channel, annotated",1000
0.319699623,0.45790379082209487,0.433,0.328,7.198170731707317,0.072,"PPO, trained on next tile, single channel, annotated",1000
0.248619155,0.42530072641948424,0.347,0.255,7.117647058823529,0.035,"PPO, trained on next tile, single channel, annotated",1000
0.323172291,0.45888572434349534,0.513,0.332,7.563253012048193,0.166,"PPO, trained on next tile, single channel, annotated",1000
0.349041829,0.4661040313843808,0.486,0.36,8.658333333333333,0.139,"PPO, trained on next tile, single channel, annotated",1000
0.281320326,0.44247211497434014,0.538,0.288,6.597222222222222,0.143,"PPO, trained on next tile, single channel, annotated",1000
0.337891042,0.46427067876019285,0.539,0.347,7.46685878962536,0.163,"PPO, trained on next tile, single channel, annotated",1000
0.371012138,0.4732501339425853,0.542,0.381,7.456692913385827,0.094,"PPO, trained on next tile, single channel, annotated",1000
0.209037908,0.40187106427724995,0.268,0.213,5.291079812206573,0.055,"PPO, trained on next tile, single channel, annotated",1000
0.24000039,0.4203445207243077,0.342,0.247,8.06072874493927,0.041,"PPO, trained on next tile, single channel, annotated",1000
0.344278918,0.4636770268606795,0.462,0.356,9.365168539325843,0.111,"PPO, trained on next tile, single channel, annotated",1000
0.28838167,0.44556424581305343,0.387,0.296,7.320945945945946,0.05,"PPO, trained on next tile, single channel, annotated",1000
0.29521759399999997,0.446537082686004,0.454,0.306,10.022875816993464,0.112,"PPO, trained on next tile, single channel, annotated",1000
0.330648457,0.46107204687248404,0.444,0.34,7.823529411764706,0.073,"PPO, trained on next tile, single channel, annotated",1000
0.27157502899999997,0.4368950461132584,0.4,0.279,7.56989247311828,0.068,"PPO, trained on next tile, single channel, annotated",1000
0.26139766200000003,0.4322879213053793,0.435,0.268,7.007462686567164,0.035,"PPO, trained on next tile, single channel, annotated",1000
0.25279649400000004,0.42761671495279974,0.387,0.26,7.880769230769231,0.036,"PPO, trained on next tile, single channel, annotated",1000
0.405234783,0.4793346467581619,0.609,0.418,8.686602870813397,0.112,"PPO, trained on next tile, single channel, annotated",1000
0.317725816,0.4562070105466072,0.457,0.327,8.067278287461773,0.115,"PPO, trained on next tile, single channel, annotated",1000
0.22045430800000002,0.4097759714641516,0.403,0.225,5.746666666666667,0.08,"PPO, trained on next tile, single channel, annotated",1000
0.281310959,0.4407878754827557,0.418,0.291,9.470790378006873,0.068,"PPO, trained on next tile, single channel, annotated",1000
0.280794535,0.44059233315443747,0.39,0.289,8.076124567474048,0.067,"PPO, trained on next tile, single channel, annotated",1000
0.240158611,0.4200310082736745,0.314,0.247,7.8785425101214575,0.035,"PPO, trained on next tile, single channel, annotated",1000
0.09985548200000001,0.2963414097262812,0.115,0.102,5.980392156862745,0.0,"PPO, trained on next tile, single channel, annotated",1000
0.267685548,0.4345127708361973,0.456,0.276,8.568840579710145,0.086,"PPO, trained on next tile, single channel, annotated",1000
0.124041415,0.3248961815120282,0.17,0.128,8.796875,0.013,"PPO, trained on next tile, single channel, annotated",1000
0.301402761,0.4508678586684883,0.413,0.309,6.993527508090615,0.066,"PPO, trained on next tile, single channel, annotated",1000
0.15261602400000002,0.35441480804856534,0.268,0.157,7.942675159235669,0.042,"PPO, trained on next tile, single channel, annotated",1000
0.334432441,0.46314433743390887,0.465,0.343,7.104956268221574,0.087,"PPO, trained on next tile, single channel, annotated",1000
